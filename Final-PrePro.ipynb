{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "fbfc6f2d-bb26-4e10-bd2a-09581f0ad98a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'bciexp', 'subject'])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trial Based Data Pre-Processing\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import mne \n",
    "mne.set_log_level('error')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib qt\n",
    "TrialData = loadmat('P02.mat')\n",
    "type(TrialData)\n",
    "TrialData.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9c15493d-c9ac-4bb4-8c57-d6a1174bcea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([[array(['P7'], dtype='<U2')],\n",
      "         [array(['P5'], dtype='<U2')],\n",
      "         [array(['P3'], dtype='<U2')],\n",
      "         [array(['P4'], dtype='<U2')],\n",
      "         [array(['P6'], dtype='<U2')],\n",
      "         [array(['P8'], dtype='<U2')],\n",
      "         [array(['PO7'], dtype='<U3')],\n",
      "         [array(['PO3'], dtype='<U3')],\n",
      "         [array(['PO4'], dtype='<U3')],\n",
      "         [array(['PO8'], dtype='<U3')],\n",
      "         [array(['O1'], dtype='<U2')],\n",
      "         [array(['O2'], dtype='<U2')]], dtype=object)]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thake\\AppData\\Local\\Temp\\ipykernel_32964\\220430124.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  sfreq = float(BCI['srate'][0, 0])  # Sampling frequency\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144, 12, 4000)\n"
     ]
    }
   ],
   "source": [
    "#filtering with MNE lib\n",
    "\n",
    "BCI = TrialData['bciexp']\n",
    "EEGData = BCI['data'][0,0] #nChannles x nSamples x nTrials\n",
    "print(BCI['label'])\n",
    "sfreq = float(BCI['srate'][0, 0])  # Sampling frequency\n",
    "n_channels = EEGData.shape[0]\n",
    "#ch_names = BCI['label'][0,0] # Dummy channel names, replace as needed\n",
    "\n",
    "ch_names = ['P7', 'P5', 'P3', 'P4','P6', 'P8', 'PO7', 'PO3', 'PO4', 'PO8', 'O1', 'O2']\n",
    "info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='eeg')\n",
    "\n",
    "# Reshape the data to (nTrials, nChannels, nSamples) as required by MNE\n",
    "EEGData_mne = np.transpose(EEGData, (2, 0, 1))\n",
    "\n",
    "# Create MNE EpochsArray object\n",
    "epochs = mne.EpochsArray(EEGData_mne, info)\n",
    "\n",
    "# Now apply the filter using MNE's filter function\n",
    "filtered_epochs = epochs.filter(l_freq=1, h_freq=15, fir_design='firwin', filter_length='auto')\n",
    "#filtered_epochs = filtered_epochs.resample(64)\n",
    "# To visualize or further process filtered data\n",
    "filtered_data = filtered_epochs.get_data()\n",
    "print(filtered_data.shape)  # This will still be (nTrials, nChannels, nSamples)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "70200a56-693b-4d5c-b81e-6cd0260a6551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "stim_id = BCI['stim'][0,0]\n",
    "intention = BCI['intention'][0,0]\n",
    "Expec = BCI['expected'][0,0]\n",
    "Target = BCI['targetside'][0,0]\n",
    "\n",
    "# Assuming `EEG_data` is your filtered and resampled EEG data\n",
    "# stim, intention, targetside are your other fields\n",
    "n_trials = filtered_data.shape[0]\n",
    "print(n_trials)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7852b15a-fd68-4bf1-8756-fa7bc0731a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 12, 250)\n",
      "Condition labels: [1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "#Re-epoching of data\n",
    "\n",
    "# Parameters for re-epoching\n",
    "tmin, tmax = -0.2, 0.8  # Time window around the stimulus (200 ms before, 800 ms after)\n",
    "sfreq = 250  # Sampling frequency\n",
    "n_trials = filtered_data.shape[0]  # Total number of trials\n",
    "condition_labels = []  # To store labels for each re-epoch based on the four conditions\n",
    "\n",
    "# Create an empty list to hold re-epoch data\n",
    "re_epoch_data = []\n",
    "\n",
    "# Loop through each trial\n",
    "for trial_id in range(n_trials):\n",
    "    EEG_trial = filtered_data[trial_id, :, :]  # Extract the EEG data for this trial\n",
    "\n",
    "    # Get the stimulus onsets and target side for this trial\n",
    "    stim_ch1 = stim_id[0, :, trial_id]  # Stimulus channel 1\n",
    "    stim_ch2 = stim_id[1, :, trial_id]  # Stimulus channel 2\n",
    "    #targetside_trial = Target[0, :, trial_id]  # Target side for this trial\n",
    "\n",
    "    # Find the indices (sample points) where stimulus onset occurs\n",
    "    stim_onsets_ch1 = np.where(stim_ch1 == 1)[0]  # Stimulus onset for Ch1\n",
    "    stim_onsets_ch2 = np.where(stim_ch2 == 1)[0]  # Stimulus onset for Ch2\n",
    "\n",
    "    # Combine stimulus onsets and create a list of (onset, stim_type) for labeling\n",
    "    all_stimuli_onsets = [(onset, 1) for onset in stim_onsets_ch1] + \\\n",
    "                         [(onset, 2) for onset in stim_onsets_ch2]\n",
    "\n",
    "    # Sort all stimuli onsets by time (ascending order)\n",
    "    all_stimuli_onsets.sort(key=lambda x: x[0])\n",
    "\n",
    "    # Loop through each stimulus onset to re-epoch the data\n",
    "    for onset, stim_type in all_stimuli_onsets:\n",
    "        # Convert onset to seconds\n",
    "        onset_sec = onset / sfreq\n",
    "\n",
    "        # Find the sample indices for the time window around the stimulus onset\n",
    "        start_sample = int(onset + tmin * sfreq)\n",
    "        end_sample = int(onset + tmax * sfreq)\n",
    "\n",
    "        # Ensure indices are within bounds\n",
    "        if start_sample >= 0 and end_sample < EEG_trial.shape[1]:\n",
    "            # Extract the EEG segment for this stimulus onset\n",
    "            re_epoch = EEG_trial[:, start_sample:end_sample]\n",
    "\n",
    "            # Append to re-epoch data\n",
    "            re_epoch_data.append(re_epoch)\n",
    "\n",
    "           # Append the stimulus type label (1 for Ch1, 2 for Ch2)\n",
    "            condition_labels.append(stim_type)\n",
    "\n",
    "# Convert the re-epoch data list to a NumPy array (n_epochs, n_channels, n_samples)\n",
    "re_epoch_data = np.array(re_epoch_data)\n",
    "print(re_epoch_data.shape)\n",
    "# Create a new MNE EpochsArray object with re-epoch data\n",
    "re_epochs = mne.EpochsArray(re_epoch_data, info)\n",
    "re_epochs = re_epochs.get_data()\n",
    "# Print the re-epoch shape and condition labels\n",
    "#print(\"Re-epoch data shape:\", re_epoch_data.shape)\n",
    "print(\"Condition labels:\", condition_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34a29682-367a-44ae-929c-fa10e17f96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the Trial Based Data\n",
    "\n",
    "# Parameters for plotting\n",
    "trial_id = 3  # Select the trial you want to plot\n",
    "channel_id = 3  # Select the specific channel you want to plot (e.g., 3rd channel)\n",
    "tmin, tmax = -0.2, 0.8  # Time window used in re-epoching\n",
    "sfreq = 250  # Sampling frequency\n",
    "\n",
    "# Extract the single trial and single channel data\n",
    "single_trial = re_epoch_data[trial_id, channel_id, :]  # Extract a specific trial and channel\n",
    "\n",
    "# Generate the time vector corresponding to tmin and tmax\n",
    "n_samples = single_trial.shape[0]\n",
    "time = np.linspace(tmin, tmax, n_samples)  # Time array for x-axis (in seconds)\n",
    "\n",
    "# Baseline correction: Subtract the mean of the pre-stimulus period (e.g., tmin to 0)\n",
    "baseline_start = int((tmin - tmin) * sfreq)  # Index of the start of the baseline (relative to tmin)\n",
    "baseline_end = int((0 - tmin) * sfreq)  # Index of the end of the baseline (0 seconds)\n",
    "baseline_mean = np.mean(single_trial[baseline_start:baseline_end])  # Calculate the baseline mean\n",
    "\n",
    "# Apply baseline correction\n",
    "single_trial_baseline_corrected = single_trial - baseline_mean\n",
    "\n",
    "# Plot the single channel data (with baseline correction)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time, single_trial_baseline_corrected, label=ch_names[channel_id], color='b')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('EEG Amplitude (µV)')\n",
    "plt.title(f'Trial {trial_id + 1} - Channel {ch_names[channel_id]} (Baseline Corrected)')\n",
    "\n",
    "# Add a grid for better visualization\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9b7ae0d9-ca8a-4bce-bd0a-292359b8bb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Averaged data shape for label 1: (144, 12, 250)\n",
      "Averaged data shape for label 2: (144, 12, 250)\n"
     ]
    }
   ],
   "source": [
    "#averaging the every 10 trials based on stim channel 1 & 2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize lists to store the averaged data\n",
    "avg_label_1_per_group = []\n",
    "avg_label_2_per_group = []\n",
    "\n",
    "# Number of trials per group\n",
    "group_size = 10\n",
    "\n",
    "# Loop over the data in chunks of 10 trials\n",
    "for i in range(0, len(re_epoch_data), group_size):\n",
    "    # Extract the current group of 10 trials\n",
    "    group_data = re_epoch_data[i:i + group_size]\n",
    "    group_labels = condition_labels[i:i + group_size]\n",
    "    \n",
    "    # Check if we have exactly 10 trials in this group\n",
    "    if len(group_data) < group_size:\n",
    "        continue  # Skip if we have fewer than 10 trials at the end\n",
    "    \n",
    "    # Separate trials by label within the group\n",
    "    trials_label_1 = [group_data[j] for j in range(group_size) if group_labels[j] == 1]\n",
    "    trials_label_2 = [group_data[j] for j in range(group_size) if group_labels[j] == 2]\n",
    "    \n",
    "    # Ensure we have 5 trials of each label before averaging\n",
    "    if len(trials_label_1) == 5 and len(trials_label_2) == 5:\n",
    "        # Compute the averages for label \"1\" and label \"2\" trials within this group\n",
    "        avg_label_1 = np.mean(trials_label_1, axis=0)\n",
    "        avg_label_2 = np.mean(trials_label_2, axis=0)\n",
    "        \n",
    "        # Append to lists\n",
    "        avg_label_1_per_group.append(avg_label_1)\n",
    "        avg_label_2_per_group.append(avg_label_2)\n",
    "    else:\n",
    "        print(f\"Warning: Skipped group {i//group_size + 1} due to imbalance in labels\")\n",
    "\n",
    "# Convert the lists to NumPy arrays\n",
    "avg_label_1_per_group = np.array(avg_label_1_per_group)  # Shape (144, n_channels, n_samples)\n",
    "avg_label_2_per_group = np.array(avg_label_2_per_group)  # Shape (144, n_channels, n_samples)\n",
    "\n",
    "print(\"Averaged data shape for label 1:\", avg_label_1_per_group.shape)\n",
    "print(\"Averaged data shape for label 2:\", avg_label_2_per_group.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27662159-bdfd-4543-9f2d-cc751a1c7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the averaged data sequence and channel wise\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "sequence_id = 55  # Choose a specific sequence (e.g., the first sequence out of 144)\n",
    "channel_id = 8  # Choose a specific channel to plot\n",
    "tmin, tmax = -0.2, 0.8  # Time window\n",
    "sfreq = 250  # Sampling frequency\n",
    "time = np.linspace(tmin, tmax, avg_label_1_per_group.shape[2])  # Time vector for x-axis\n",
    "\n",
    "# Plot for the chosen sequence and channel\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot for label 1 (average of 5 trials with label 1 in the selected sequence)\n",
    "plt.plot(time, avg_label_1_per_group[sequence_id, channel_id, :], label='Label 1 Avg', color='b')\n",
    "\n",
    "# Plot for label 2 (average of 5 trials with label 2 in the selected sequence)\n",
    "plt.plot(time, avg_label_2_per_group[sequence_id, channel_id, :], label='Label 2 Avg', color='r')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('EEG Amplitude (µV)')\n",
    "plt.title(f'Averaged EEG Signal - Sequence {sequence_id + 1} - Channel {channel_id}')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "219c3eb4-b1ab-4f5e-af08-a21ba481877e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold accuracy: 96.55%\n",
      "Fold accuracy: 96.55%\n",
      "Fold accuracy: 93.10%\n",
      "Fold accuracy: 93.10%\n",
      "Fold accuracy: 93.10%\n",
      "Fold accuracy: 93.10%\n",
      "Fold accuracy: 89.66%\n",
      "Fold accuracy: 93.10%\n",
      "Fold accuracy: 89.29%\n",
      "Fold accuracy: 96.43%\n",
      "Cross-Validation Accuracy:, 93.40%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assume avg_label_1_per_group and avg_label_2_per_group are (144, n_channels, n_samples)\n",
    "# Prepare data and labels\n",
    "data = np.concatenate([avg_label_1_per_group, avg_label_2_per_group], axis=0)  # (288, n_channels, n_samples)\n",
    "labels = np.array([1] * 144 + [2] * 144)  # Labels for each sample (1 for avg_label_1, 2 for avg_label_2)\n",
    "\n",
    "# Flatten each sequence for simplicity (you can also extract features as needed)\n",
    "data_flat = data.reshape(data.shape[0], -1)  # Reshape to (288, n_channels * n_samples)\n",
    "\n",
    "# Set up cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "\n",
    "# Cross-validation loop\n",
    "for train_index, test_index in kf.split(data_flat):\n",
    "    X_train, X_test = data_flat[train_index], data_flat[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    # Initialize and train SVM classifier\n",
    "    clf = SVC(kernel='linear')  # Choose kernel type as appropriate\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f'Fold accuracy: {accuracy * 100:.2f}%')\n",
    "# Print average cross-validation accuracy\n",
    "print(f'Cross-Validation Accuracy:, {np.mean(accuracies) * 100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
